from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command
from bot.keyboards import get_main_keyboard, get_article_keyboard, get_filter_keyboard
from core.rag_engine import RagEngine
from core.scraper import HabrScraper
from core.llm_service import llm_service
import logging

router = Router()
logger = logging.getLogger(__name__)

rag = RagEngine()
scraper = HabrScraper()

# Simple in-memory storage for user filters (chat_id -> filter_dict)
user_filters = {}

@router.message(Command("start"))
async def cmd_start(message: Message):
    await message.answer(
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ AI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ ÑÑ‚Ğ°Ñ‚ÑŒÑĞ¼ Ğ¥Ğ°Ğ±Ñ€Ğ°.\n"
        "ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¼Ğ½Ğµ ÑĞ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ»Ğ¸ Ñ‚ĞµĞ¼Ñƒ, Ğ¸ Ñ Ğ½Ğ°Ğ¹Ğ´Ñƒ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹.\n"
        "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ 'ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹' Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ÑĞ²ĞµĞ¶Ğ¸Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹.",
        reply_markup=get_main_keyboard()
    )

@router.message(F.text == "ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹")
async def sync_knowledge_base(message: Message):
    status_msg = await message.answer("ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ ÑĞ²ĞµĞ¶Ğ¸Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ñ Ğ¥Ğ°Ğ±Ñ€Ğ°...")
    try:
        articles = scraper.get_latest_articles(limit=5)
        if articles:
            rag.add_documents(articles)
            await status_msg.edit_text(f"âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(articles)} ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ² Ğ±Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹!")
        else:
            await status_msg.edit_text("âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ….")
    except Exception as e:
        logger.error(f"Sync error: {e}")
        await status_msg.edit_text("âŒ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ±Ğ°Ğ·Ñ‹.")

@router.message(F.text == "âš™ï¸ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
async def show_filters(message: Message):
    current_filters = user_filters.get(message.chat.id, {})
    filter_text = "ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹:\n"
    if not current_filters:
        filter_text += "ĞĞµÑ‚ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²."
    else:
        for k, v in current_filters.items():
            filter_text += f"- {k}: {v}\n"
            
    await message.answer(filter_text, reply_markup=get_filter_keyboard())

@router.callback_query(F.data.startswith("filter:"))
async def handle_filter_callback(callback: CallbackQuery):
    action = callback.data.split(":")[1]
    
    if action == "reset":
        user_filters.pop(callback.message.chat.id, None)
        await callback.message.edit_text("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½Ñ‹.", reply_markup=get_filter_keyboard())
    elif action == "date":
        # Placeholder for date filtering logic customization
        # making it simple for now
        await callback.answer("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾ (mock).")
    
    await callback.answer()

@router.message(F.text == "â„¹ï¸ Ğ Ğ±Ğ¾Ñ‚Ğµ")
async def about_bot(message: Message):
    await message.answer(
        "Ğ­Ñ‚Ğ¾Ñ‚ Ğ±Ğ¾Ñ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ RAG (Retrieval-Augmented Generation) Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ².\n"
        "Ğ¡Ñ‚ĞµĞº: Python, aiogram, ChromaDB, SentenceTransformers."
    )

@router.callback_query(F.data.startswith("similar:"))
async def handle_similar_articles(callback: CallbackQuery):
    # Format: similar:ShortTitle
    # We need to find the full title or just use the short one for search
    short_title = callback.data.split(":", 1)[1]
    await callback.message.answer(f"ğŸ” Ğ˜Ñ‰Ñƒ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸, Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ Ğ½Ğ°: {short_title}...")
    
    results = rag.get_recommendations(short_title, n_results=3)
    await send_search_results(callback.message, results)
    await callback.answer()

@router.callback_query(F.data.startswith("quiz:"))
async def handle_quiz(callback: CallbackQuery):
    short_title = callback.data.split(":", 1)[1]
    
    # Try to fetch article content from DB for better quiz
    results = rag.search(short_title, n_results=1)
    content = results[0]['content'] if results else ""
    
    quiz_text = llm_service.generate_quiz(short_title, content)
    await callback.message.answer(quiz_text)
    await callback.answer()

async def send_search_results(message: Message, results: list):
    if not results:
        await message.answer("ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
        return

    for idx, res in enumerate(results, 1):
        meta = res['metadata']
        # Expanded snippet as summary
        # Prefer RSS description (clean summary) over random chunk
        description = meta.get('description', '')
        if len(description) > 50:
            snippet = description[:500] + ("..." if len(description) > 500 else "")
        else:
            # Fallback to chunk content if description is missing/too short
            snippet = res['content'][:400].replace('\n', ' ') + "..."
        
        await message.answer(
            f"**{idx}. {meta['title']}**\n\n"
            f"ğŸ“ **ĞĞ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ:**\n{snippet}\n\n"
            f"ğŸ“… {meta['pub_date']}\n"
            f"âœï¸ {meta.get('creator', 'Habr User')}",
            reply_markup=get_article_keyboard(meta['link'], meta['title']),
            parse_mode="Markdown"
        )

@router.message()
async def handle_search(message: Message):
    query = message.text
    await message.bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    filters = user_filters.get(message.chat.id)
    results = rag.search(query, n_results=3, filters=filters)
    
    # Generate AI summary if results found
    if results and llm_service.client:
        # Prepare context from results
        context = "\n\n".join([f"Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ: {r['metadata']['title']}\n{r['content'][:500]}" for r in results[:2]])
        try:
            summary = llm_service.generate_summary(context, query)
            await message.answer(f"ğŸ“ **ĞšÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ¿Ğ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ:**\n\n{summary}\n\n---\n")
        except:
            pass  # If summary fails, just show results
    
    await send_search_results(message, results)

